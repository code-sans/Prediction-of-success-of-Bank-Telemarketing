{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7df4c1d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:12.930020Z",
     "iopub.status.busy": "2024-11-24T08:25:12.929643Z",
     "iopub.status.idle": "2024-11-24T08:25:13.919890Z",
     "shell.execute_reply": "2024-11-24T08:25:13.918559Z"
    },
    "papermill": {
     "duration": 1.00693,
     "end_time": "2024-11-24T08:25:13.922324",
     "exception": false,
     "start_time": "2024-11-24T08:25:12.915394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/predict-the-success-of-bank-telemarketing/sample_submission.csv\n",
      "/kaggle/input/predict-the-success-of-bank-telemarketing/train.csv\n",
      "/kaggle/input/predict-the-success-of-bank-telemarketing/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a28a660",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:13.949223Z",
     "iopub.status.busy": "2024-11-24T08:25:13.948706Z",
     "iopub.status.idle": "2024-11-24T08:25:15.878105Z",
     "shell.execute_reply": "2024-11-24T08:25:15.877103Z"
    },
    "papermill": {
     "duration": 1.944993,
     "end_time": "2024-11-24T08:25:15.880618",
     "exception": false,
     "start_time": "2024-11-24T08:25:13.935625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the Libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "from datetime import datetime\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d21316a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:15.907080Z",
     "iopub.status.busy": "2024-11-24T08:25:15.906531Z",
     "iopub.status.idle": "2024-11-24T08:25:16.100399Z",
     "shell.execute_reply": "2024-11-24T08:25:16.099135Z"
    },
    "papermill": {
     "duration": 0.209753,
     "end_time": "2024-11-24T08:25:16.103096",
     "exception": false,
     "start_time": "2024-11-24T08:25:15.893343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_data = pd.read_csv('/kaggle/input/predict-the-success-of-bank-telemarketing/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/predict-the-success-of-bank-telemarketing/test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdab75da",
   "metadata": {
    "papermill": {
     "duration": 0.011768,
     "end_time": "2024-11-24T08:25:16.126730",
     "exception": false,
     "start_time": "2024-11-24T08:25:16.114962",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " # **EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aab4ccee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:16.152669Z",
     "iopub.status.busy": "2024-11-24T08:25:16.152283Z",
     "iopub.status.idle": "2024-11-24T08:25:16.156658Z",
     "shell.execute_reply": "2024-11-24T08:25:16.155640Z"
    },
    "papermill": {
     "duration": 0.019925,
     "end_time": "2024-11-24T08:25:16.158803",
     "exception": false,
     "start_time": "2024-11-24T08:25:16.138878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(train_data.head())\n",
    "# print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c14fe528",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:16.184940Z",
     "iopub.status.busy": "2024-11-24T08:25:16.184531Z",
     "iopub.status.idle": "2024-11-24T08:25:16.189128Z",
     "shell.execute_reply": "2024-11-24T08:25:16.187841Z"
    },
    "papermill": {
     "duration": 0.019937,
     "end_time": "2024-11-24T08:25:16.191290",
     "exception": false,
     "start_time": "2024-11-24T08:25:16.171353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Basic info \n",
    "# print(train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37f1779b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:16.216946Z",
     "iopub.status.busy": "2024-11-24T08:25:16.216545Z",
     "iopub.status.idle": "2024-11-24T08:25:16.221536Z",
     "shell.execute_reply": "2024-11-24T08:25:16.220250Z"
    },
    "papermill": {
     "duration": 0.021618,
     "end_time": "2024-11-24T08:25:16.224647",
     "exception": false,
     "start_time": "2024-11-24T08:25:16.203029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Summary statistics\n",
    "# print(train_data.describe())\n",
    "\n",
    "\n",
    "# #Check for Missing Values\n",
    "# print(train_data.isnull().sum())\n",
    "\n",
    "# # Can clearly Comment that poutcome and contact has the highest number of NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "678a3f3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:16.250156Z",
     "iopub.status.busy": "2024-11-24T08:25:16.249721Z",
     "iopub.status.idle": "2024-11-24T08:25:16.255211Z",
     "shell.execute_reply": "2024-11-24T08:25:16.254273Z"
    },
    "papermill": {
     "duration": 0.020583,
     "end_time": "2024-11-24T08:25:16.257431",
     "exception": false,
     "start_time": "2024-11-24T08:25:16.236848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(train_data['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3b490ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:16.283181Z",
     "iopub.status.busy": "2024-11-24T08:25:16.282763Z",
     "iopub.status.idle": "2024-11-24T08:25:16.289286Z",
     "shell.execute_reply": "2024-11-24T08:25:16.288124Z"
    },
    "papermill": {
     "duration": 0.021821,
     "end_time": "2024-11-24T08:25:16.291572",
     "exception": false,
     "start_time": "2024-11-24T08:25:16.269751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Set general figure size for all plots\n",
    "# plt.figure(figsize=(15, 12))\n",
    "# train= train_data\n",
    "\n",
    "# # 1. Distribution of Target Variable (Subscribed or Not)\n",
    "# plt.subplot(3, 3, 1)\n",
    "# sns.countplot(x='target', data=train, palette='Set2')\n",
    "# plt.title('Distribution of Target Variable')\n",
    "# plt.xlabel('Subscribed to Term Deposit')\n",
    "# plt.ylabel('Count')\n",
    "\n",
    "# # 2. Age Distribution\n",
    "# plt.subplot(3, 3, 2)\n",
    "# sns.histplot(train['age'], bins=20, kde=True, color='purple')\n",
    "# plt.title('Age Distribution')\n",
    "# plt.xlabel('Age')\n",
    "# plt.ylabel('Frequency')\n",
    "\n",
    "# # 3. Balance Distribution\n",
    "# plt.subplot(3, 3, 3)\n",
    "# sns.histplot(train['balance'], bins=30, kde=True, color='green')\n",
    "# plt.title('Balance Distribution')\n",
    "# plt.xlabel('Balance (Euros)')\n",
    "# plt.ylabel('Frequency')\n",
    "\n",
    "# # 4. Marital Status vs Subscription\n",
    "# plt.subplot(3, 3, 4)\n",
    "# sns.countplot(x='marital', hue='target', data=train, palette='Set1')\n",
    "# plt.title('Marital Status vs Subscription')\n",
    "# plt.xlabel('Marital Status')\n",
    "# plt.ylabel('Count')\n",
    "\n",
    "# # 5. Education vs Subscription\n",
    "# plt.subplot(3, 3, 5)\n",
    "# sns.countplot(x='education', hue='target', data=train, palette='Set3')\n",
    "# plt.title('Education Level vs Subscription')\n",
    "# plt.xlabel('Education Level')\n",
    "# plt.ylabel('Count')\n",
    "# plt.xticks(rotation=45)\n",
    "\n",
    "# # 6. Housing Loan vs Subscription\n",
    "# plt.subplot(3, 3, 6)\n",
    "# sns.boxplot(data=train, x='target', y='balance', palette='Set1')\n",
    "# plt.yscale('log') \n",
    "# plt.title(\"Balance Distribution by Subscription Status\")\n",
    "# plt.xlabel(\"Subscribed to Term Deposit\")\n",
    "# plt.ylabel(\"Balance (Euros)\")\n",
    "\n",
    "\n",
    "# # 7. Previous Outcome vs Subscription\n",
    "# plt.subplot(3, 3, 7)\n",
    "# sns.countplot(x='poutcome', hue='target', data=train, palette='viridis')\n",
    "# plt.title('Previous Campaign Outcome vs Subscription')\n",
    "# plt.xlabel('Previous Campaign Outcome')\n",
    "# plt.ylabel('Count')\n",
    "\n",
    "# # 8. Age vs Balance (Scatter Plot)\n",
    "# plt.subplot(3, 3, 8)\n",
    "# sns.countplot(x='housing', hue='target', data=train, palette='coolwarm')\n",
    "# plt.title('Housing Loan vs Subscription')\n",
    "# plt.xlabel('Has Housing Loan')\n",
    "# plt.ylabel('Count')\n",
    "\n",
    "\n",
    "# # 9. Last Contact Duration vs Subscription\n",
    "# plt.subplot(3, 3, 9)\n",
    "# sns.boxplot(x='target', y='duration', data=train, palette='Set1')\n",
    "# plt.title('Last Contact Duration vs Subscription')\n",
    "# plt.xlabel('Subscribed to Term Deposit')\n",
    "# plt.ylabel('Duration of Last Contact (Seconds)')\n",
    "# train_data = train \n",
    "\n",
    "# # Adjust layout to prevent overlap\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Show all plots\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6d71072",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:16.316641Z",
     "iopub.status.busy": "2024-11-24T08:25:16.316223Z",
     "iopub.status.idle": "2024-11-24T08:25:16.321744Z",
     "shell.execute_reply": "2024-11-24T08:25:16.320375Z"
    },
    "papermill": {
     "duration": 0.020775,
     "end_time": "2024-11-24T08:25:16.324154",
     "exception": false,
     "start_time": "2024-11-24T08:25:16.303379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "###INSIGHTS\n",
    "\n",
    "# People who have more balance in their account they are showing more interest in subscirbing the term deposit\n",
    "# Those who are single are subscribing more comparative to married people\n",
    "# People have have tertiary level oof education, they are subscribing FD more\n",
    "# If previos outcome is a success then no. of people subscribed it more , intersting is failure\n",
    "# of previous outcome is also resulting in YES manytimes\n",
    "\n",
    "# Those whose calls cut in less than 300-350 seconds, mostly they have not subscribed although there are many exceptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf8e3ca3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:16.349950Z",
     "iopub.status.busy": "2024-11-24T08:25:16.348983Z",
     "iopub.status.idle": "2024-11-24T08:25:16.354386Z",
     "shell.execute_reply": "2024-11-24T08:25:16.353148Z"
    },
    "papermill": {
     "duration": 0.020432,
     "end_time": "2024-11-24T08:25:16.356388",
     "exception": false,
     "start_time": "2024-11-24T08:25:16.335956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(6, 4))\n",
    "# sns.countplot(data=train_data, x='job', hue='target', palette='Set2')\n",
    "# plt.title(\"Job Type vs. Subscription Rate\")\n",
    "# plt.xlabel(\"Job Type\")\n",
    "# plt.ylabel(\"Count\")\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.legend(title='Subscribed to Term Deposit')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # age_bins = [0, 20, 30, 40, 50, 60, 70, 80, 100]\n",
    "# # age_labels = ['<20', '20-30', '30-40', '40-50', '50-60', '60-70', '70-80', '80+']\n",
    "# # train_data['age_group'] = pd.cut(train_data['age'], bins=age_bins, labels=age_labels)\n",
    "\n",
    "# # plt.figure(figsize=(5, 3))\n",
    "# # sns.countplot(data=train_data, x='age_group', hue='target', palette='cool')\n",
    "# # plt.title(\"Age Group vs. Subscription Rate\")\n",
    "# # plt.xlabel(\"Age Group\")\n",
    "# # plt.ylabel(\"Count\")\n",
    "# # plt.legend(title='Subscribed to Term Deposit')\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dd5611b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:16.381304Z",
     "iopub.status.busy": "2024-11-24T08:25:16.380906Z",
     "iopub.status.idle": "2024-11-24T08:25:16.385837Z",
     "shell.execute_reply": "2024-11-24T08:25:16.384616Z"
    },
    "papermill": {
     "duration": 0.020124,
     "end_time": "2024-11-24T08:25:16.388288",
     "exception": false,
     "start_time": "2024-11-24T08:25:16.368164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ##INSIGHTS \n",
    "\n",
    "# People are more from age group 20-60 but the ratio of subscription of Term Deposit is more in <20 or 60+ age .\n",
    "# blue-collar/labour has least yes ratio whereas the students,self employed ,retired and housemaids has the highest ratio of no vs yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec9c6ee5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:16.413550Z",
     "iopub.status.busy": "2024-11-24T08:25:16.413011Z",
     "iopub.status.idle": "2024-11-24T08:25:16.417965Z",
     "shell.execute_reply": "2024-11-24T08:25:16.416876Z"
    },
    "papermill": {
     "duration": 0.02009,
     "end_time": "2024-11-24T08:25:16.420353",
     "exception": false,
     "start_time": "2024-11-24T08:25:16.400263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Create a new feature based on age and balance interaction\n",
    "# train_data['balance_duration'] = train_data['balance'] * train_data['duration']\n",
    "\n",
    "# # Create a new feature based on age and balance interaction\n",
    "# test_data['balance_duration'] = test_data['balance'] * test_data['duration']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d6f489",
   "metadata": {
    "papermill": {
     "duration": 0.011811,
     "end_time": "2024-11-24T08:25:16.444430",
     "exception": false,
     "start_time": "2024-11-24T08:25:16.432619",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Tried to make new column/ feature extraction but did not got the good aaccuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce5eb793",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:16.469434Z",
     "iopub.status.busy": "2024-11-24T08:25:16.469008Z",
     "iopub.status.idle": "2024-11-24T08:25:16.473772Z",
     "shell.execute_reply": "2024-11-24T08:25:16.472627Z"
    },
    "papermill": {
     "duration": 0.020234,
     "end_time": "2024-11-24T08:25:16.476147",
     "exception": false,
     "start_time": "2024-11-24T08:25:16.455913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(train_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb496a58",
   "metadata": {
    "papermill": {
     "duration": 0.01145,
     "end_time": "2024-11-24T08:25:16.499302",
     "exception": false,
     "start_time": "2024-11-24T08:25:16.487852",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f39fe550",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:16.525104Z",
     "iopub.status.busy": "2024-11-24T08:25:16.524674Z",
     "iopub.status.idle": "2024-11-24T08:25:16.719181Z",
     "shell.execute_reply": "2024-11-24T08:25:16.717375Z"
    },
    "papermill": {
     "duration": 0.21049,
     "end_time": "2024-11-24T08:25:16.721901",
     "exception": false,
     "start_time": "2024-11-24T08:25:16.511411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Fill missing values for categorical features with 'unknown' and convert to string type\n",
    "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
    "train_data[categorical_columns] = train_data[categorical_columns].fillna('unknown').astype(str)\n",
    "test_data[categorical_columns] = test_data[categorical_columns].fillna('unknown').astype(str)\n",
    "\n",
    "# Fill missing numerical values with column mean\n",
    "numerical_columns = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']\n",
    "# train_data[numerical_columns] = train_data[numerical_columns].apply(lambda x: x.fillna(x.mode()[0]))\n",
    "# test_data[numerical_columns] = test_data[numerical_columns].apply(lambda x: x.fillna(x.mode()[0]))\n",
    "train_data[numerical_columns] = train_data[numerical_columns].fillna(train_data[numerical_columns].median())\n",
    "test_data[numerical_columns] = test_data[numerical_columns].fillna(test_data[numerical_columns].median())\n",
    "\n",
    "\n",
    "# # Add interaction feature between 'balance' and 'duration'\n",
    "# train_data['balance_duration_interaction'] = train_data['balance'] * train_data['duration']\n",
    "# test_data['balance_duration_interaction'] = test_data['balance'] * test_data['duration']\n",
    "\n",
    "\n",
    "\n",
    "if 'last contact date' in train_data.columns:\n",
    "    # Convert to datetime\n",
    "    train_data['last contact date'] = pd.to_datetime(train_data['last contact date'], errors='coerce')\n",
    "    test_data['last contact date'] = pd.to_datetime(test_data['last contact date'], errors='coerce')\n",
    "    \n",
    "    # Extract day, month, and year\n",
    "    train_data['last_contact_day'] = train_data['last contact date'].dt.day\n",
    "    train_data['last_contact_month'] = train_data['last contact date'].dt.month\n",
    "    train_data['last_contact_year'] = train_data['last contact date'].dt.year\n",
    "    \n",
    "    test_data['last_contact_day'] = test_data['last contact date'].dt.day\n",
    "    test_data['last_contact_month'] = test_data['last contact date'].dt.month\n",
    "    test_data['last_contact_year'] = test_data['last contact date'].dt.year\n",
    "    \n",
    "    # Drop original 'last contact date' column\n",
    "    train_data.drop(columns=['last contact date'], inplace=True)\n",
    "    test_data.drop(columns=['last contact date'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Binary feature encoding\n",
    "binary_columns = ['default', 'housing', 'loan']\n",
    "for col in binary_columns:\n",
    "    train_data[col] = train_data[col].map({'yes': 1, 'no': 0, 'unknown': -1})\n",
    "    test_data[col] = test_data[col].map({'yes': 1, 'no': 0, 'unknown': -1})\n",
    "\n",
    "# Ordinal encoding for education\n",
    "education_map = {'unknown': 0, 'primary': 1, 'secondary': 2, 'tertiary': 3}\n",
    "train_data['education'] = train_data['education'].map(education_map).astype(int)\n",
    "test_data['education'] = test_data['education'].map(education_map).astype(int)\n",
    "# train_data.drop(columns=['contact'], inplace=True)\n",
    "# test_data.drop(columns=['contact'], inplace=True)\n",
    "# One-Hot encoding for categorical variables\n",
    "train_data = pd.get_dummies(train_data, columns=['job', 'marital', 'poutcome','contact'], drop_first=True)\n",
    "test_data = pd.get_dummies(test_data, columns=['job', 'marital', 'poutcome','contact'], drop_first=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b8d746",
   "metadata": {
    "papermill": {
     "duration": 0.011192,
     "end_time": "2024-11-24T08:25:16.744868",
     "exception": false,
     "start_time": "2024-11-24T08:25:16.733676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b11267b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:16.771543Z",
     "iopub.status.busy": "2024-11-24T08:25:16.771144Z",
     "iopub.status.idle": "2024-11-24T08:25:16.776725Z",
     "shell.execute_reply": "2024-11-24T08:25:16.775661Z"
    },
    "papermill": {
     "duration": 0.022349,
     "end_time": "2024-11-24T08:25:16.778943",
     "exception": false,
     "start_time": "2024-11-24T08:25:16.756594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# categorical_columns = ['job', 'marital', 'default','education', 'housing', 'loan', 'contact', 'poutcome']\n",
    "# numerical_columns = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']\n",
    "# train_data[categorical_columns] = train_data[categorical_columns].fillna('unknown').astype(str)\n",
    "# test_data[categorical_columns] = test_data[categorical_columns].fillna('unknown').astype(str)\n",
    "\n",
    "# train_data[numerical_columns] = train_data[numerical_columns].fillna(train_data[numerical_columns].mean())\n",
    "# test_data[numerical_columns] = test_data[numerical_columns].fillna(test_data[numerical_columns].mean())\n",
    "\n",
    "# education_map = {'unknown': 0, 'primary': 1, 'secondary': 2, 'tertiary': 3}\n",
    "# train_data['education'] = train_data['education'].map(education_map)\n",
    "# test_data['education'] = test_data['education'].map(education_map)\n",
    "\n",
    "# # Define transformers for categorical and numerical columns\n",
    "# categorical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "#     ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore'))\n",
    "# ])\n",
    "\n",
    "# numeric_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='mean')),\n",
    "#     ('scaler', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# # Combine transformers into a ColumnTransformer for preprocessing\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', numeric_transformer, numerical_columns + ['education']),\n",
    "#         ('cat', categorical_transformer, categorical_columns)\n",
    "#     ]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4fb2041",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:16.803929Z",
     "iopub.status.busy": "2024-11-24T08:25:16.803530Z",
     "iopub.status.idle": "2024-11-24T08:25:16.808350Z",
     "shell.execute_reply": "2024-11-24T08:25:16.807224Z"
    },
    "papermill": {
     "duration": 0.019933,
     "end_time": "2024-11-24T08:25:16.810468",
     "exception": false,
     "start_time": "2024-11-24T08:25:16.790535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Combine 'housing' and 'loan' into a single 'has_loan' column\n",
    "\n",
    "# train_data['has_loan'] = train_data[['housing', 'loan']].apply(lambda x: 'yes' if 1 in x.values else ('no' if 0 in x.values else 'unknown'), axis=1)\n",
    "# test_data['has_loan'] = test_data[['housing', 'loan']].apply(lambda x: 'yes' if 1 in x.values else ('no' if 0 in x.values else 'unknown'), axis=1)\n",
    "\n",
    "# # Map 'has_loan' to 1 for 'yes', 0 for 'no', and -1 for 'unknown'\n",
    "# train_data['has_loan'] = train_data['has_loan'].map({'yes': 1, 'no': 0, 'unknown': -1})\n",
    "# test_data['has_loan'] = test_data['has_loan'].map({'yes': 1, 'no': 0, 'unknown': -1})\n",
    "\n",
    "\n",
    "# train_data.drop(columns=['housing', 'loan'], inplace=True)\n",
    "# test_data.drop(columns=['housing', 'loan'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3100a6de",
   "metadata": {
    "papermill": {
     "duration": 0.011192,
     "end_time": "2024-11-24T08:25:16.833231",
     "exception": false,
     "start_time": "2024-11-24T08:25:16.822039",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The Idea here was to combine the housing loan and loan but accuracy decreased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5ebffce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:16.858673Z",
     "iopub.status.busy": "2024-11-24T08:25:16.858261Z",
     "iopub.status.idle": "2024-11-24T08:25:16.868473Z",
     "shell.execute_reply": "2024-11-24T08:25:16.867668Z"
    },
    "papermill": {
     "duration": 0.025905,
     "end_time": "2024-11-24T08:25:16.870828",
     "exception": false,
     "start_time": "2024-11-24T08:25:16.844923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# # # Convert 'last contact date' to datetime format\n",
    "# # train_data['last contact date'] = pd.to_datetime(train_data['last contact date'], errors='coerce')\n",
    "# # test_data['last contact date'] = pd.to_datetime(test_data['last contact date'], errors='coerce')\n",
    "\n",
    "# # # Calculate the number of days since last contact\n",
    "# # current_date = datetime.today()\n",
    "# # train_data['days_since_last_contact'] = (current_date - train_data['last contact date']).dt.days\n",
    "# # test_data['days_since_last_contact'] = (current_date - test_data['last contact date']).dt.days\n",
    "\n",
    "# # \n",
    "# # numerical_columns.append('days_since_last_contact')\n",
    "\n",
    "#Align train and test sets\n",
    "train_data, test_data = train_data.align(test_data, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# if 'last contact date' in train_data.columns:\n",
    "#     train_data.drop(columns=['last contact date'], inplace=True)\n",
    "#     test_data.drop(columns=['last contact date'], inplace=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4a8548d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:16.895667Z",
     "iopub.status.busy": "2024-11-24T08:25:16.895256Z",
     "iopub.status.idle": "2024-11-24T08:25:16.906236Z",
     "shell.execute_reply": "2024-11-24T08:25:16.905020Z"
    },
    "papermill": {
     "duration": 0.025976,
     "end_time": "2024-11-24T08:25:16.908613",
     "exception": false,
     "start_time": "2024-11-24T08:25:16.882637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = train_data.drop(columns='target')\n",
    "y = train_data['target'].map({'yes': 1, 'no': 0})  # Convert target to binary\n",
    "\n",
    "\n",
    "# Save original column names for later use\n",
    "# original_columns = X.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebcd8a63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:16.933807Z",
     "iopub.status.busy": "2024-11-24T08:25:16.933428Z",
     "iopub.status.idle": "2024-11-24T08:25:17.015397Z",
     "shell.execute_reply": "2024-11-24T08:25:17.014137Z"
    },
    "papermill": {
     "duration": 0.097447,
     "end_time": "2024-11-24T08:25:17.017944",
     "exception": false,
     "start_time": "2024-11-24T08:25:16.920497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc811f91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:17.042848Z",
     "iopub.status.busy": "2024-11-24T08:25:17.042433Z",
     "iopub.status.idle": "2024-11-24T08:25:17.047446Z",
     "shell.execute_reply": "2024-11-24T08:25:17.046228Z"
    },
    "papermill": {
     "duration": 0.020095,
     "end_time": "2024-11-24T08:25:17.049628",
     "exception": false,
     "start_time": "2024-11-24T08:25:17.029533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a24aaa50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:17.074917Z",
     "iopub.status.busy": "2024-11-24T08:25:17.074472Z",
     "iopub.status.idle": "2024-11-24T08:25:17.079326Z",
     "shell.execute_reply": "2024-11-24T08:25:17.078215Z"
    },
    "papermill": {
     "duration": 0.019802,
     "end_time": "2024-11-24T08:25:17.081392",
     "exception": false,
     "start_time": "2024-11-24T08:25:17.061590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62db2fa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:17.107430Z",
     "iopub.status.busy": "2024-11-24T08:25:17.106236Z",
     "iopub.status.idle": "2024-11-24T08:25:17.111459Z",
     "shell.execute_reply": "2024-11-24T08:25:17.110329Z"
    },
    "papermill": {
     "duration": 0.020316,
     "end_time": "2024-11-24T08:25:17.113468",
     "exception": false,
     "start_time": "2024-11-24T08:25:17.093152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Check the unique values in the 'has_loan' column\n",
    "# print(X_train['has_loan'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbf6000b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:17.139093Z",
     "iopub.status.busy": "2024-11-24T08:25:17.137868Z",
     "iopub.status.idle": "2024-11-24T08:25:17.143037Z",
     "shell.execute_reply": "2024-11-24T08:25:17.142091Z"
    },
    "papermill": {
     "duration": 0.020043,
     "end_time": "2024-11-24T08:25:17.145329",
     "exception": false,
     "start_time": "2024-11-24T08:25:17.125286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #correlation matrix \n",
    "\n",
    "# X_train_with_target = X_train.copy()\n",
    "# X_train_with_target['target'] = y_train \n",
    "\n",
    "# corr_matrix_with_target = X_train_with_target.corr()\n",
    "\n",
    "# plt.figure(figsize=(16, 10))\n",
    "# sns.heatmap(corr_matrix_with_target, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "# plt.title(\"Correlation Matrix Including Target Variable\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b380d8aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:17.170197Z",
     "iopub.status.busy": "2024-11-24T08:25:17.169734Z",
     "iopub.status.idle": "2024-11-24T08:25:17.174314Z",
     "shell.execute_reply": "2024-11-24T08:25:17.173249Z"
    },
    "papermill": {
     "duration": 0.019335,
     "end_time": "2024-11-24T08:25:17.176271",
     "exception": false,
     "start_time": "2024-11-24T08:25:17.156936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dba6c05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:17.207489Z",
     "iopub.status.busy": "2024-11-24T08:25:17.206656Z",
     "iopub.status.idle": "2024-11-24T08:25:21.626294Z",
     "shell.execute_reply": "2024-11-24T08:25:21.624969Z"
    },
    "papermill": {
     "duration": 4.440372,
     "end_time": "2024-11-24T08:25:21.628665",
     "exception": false,
     "start_time": "2024-11-24T08:25:17.188293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17826, number of negative: 17826\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4890\n",
      "[LightGBM] [Info] Number of data points in the train set: 35652, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 17826, number of negative: 17826\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008759 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4527\n",
      "[LightGBM] [Info] Number of data points in the train set: 35652, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 17826, number of negative: 17826\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008811 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4516\n",
      "[LightGBM] [Info] Number of data points in the train set: 35652, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 26739, number of negative: 26739\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4934\n",
      "[LightGBM] [Info] Number of data points in the train set: 53478, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best Parameters for LightGBM: {'colsample_bytree': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 102, 'num_leaves': 63, 'subsample': 0.8}\n",
      "Best Cross-Validated F1 Score for LightGBM: 0.882596618735883\n",
      "F1 Score on Validation Set: 0.7677336179052\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Initialize SMOTE for oversampling\n",
    "smote = SMOTE(random_state=42, k_neighbors=6)\n",
    "\n",
    "# Fit SMOTE on the training data\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Initialize LightGBM model\n",
    "lgb_model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# Hyperparameters for tuning\n",
    "param_grid_lgb = {\n",
    "    'n_estimators': [102],\n",
    "    'max_depth': [4],\n",
    "    'num_leaves': [63],  # Add num_leaves to grid search\n",
    "    'learning_rate': [0.1],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [ 1]\n",
    "}\n",
    "# {'colsample_bytree': 1, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'num_leaves': 63, 'subsample': 0.8}\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "grid_search_lgb = GridSearchCV(estimator=lgb_model, param_grid=param_grid_lgb,\n",
    "                               scoring='f1_macro', cv=3, n_jobs=-1)\n",
    "grid_search_lgb.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Print best parameters and best score\n",
    "print(\"Best Parameters for LightGBM:\", grid_search_lgb.best_params_)\n",
    "print(\"Best Cross-Validated F1 Score for LightGBM:\", grid_search_lgb.best_score_)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = grid_search_lgb.predict(X_val_scaled)\n",
    "\n",
    "# Evaluate model performance\n",
    "val_f1_score = f1_score(y_val, y_val_pred, average='macro')\n",
    "print(\"F1 Score on Validation Set:\", val_f1_score)\n",
    "\n",
    "# Make predictions on test data\n",
    "# test_predictions = grid_search_lgb.predict(test_data)\n",
    "\n",
    "# Create submission file\n",
    "# submission = pd.DataFrame({\n",
    "#     'id': test_data.index,\n",
    "#     'target': ['yes' if pred == 1 else 'no' for pred in test_predictions]\n",
    "# })\n",
    "\n",
    "# # Save the submission\n",
    "# submission.to_csv('submission.csv', index=False)\n",
    "# print(\"Submission file created: submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ccb1c29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:21.655829Z",
     "iopub.status.busy": "2024-11-24T08:25:21.654949Z",
     "iopub.status.idle": "2024-11-24T08:25:21.661150Z",
     "shell.execute_reply": "2024-11-24T08:25:21.659983Z"
    },
    "papermill": {
     "duration": 0.022232,
     "end_time": "2024-11-24T08:25:21.663515",
     "exception": false,
     "start_time": "2024-11-24T08:25:21.641283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters : {'colsample_bytree': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 102, 'num_leaves': 63, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "best_params = grid_search_lgb.best_params_\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters :\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48018725",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:21.692935Z",
     "iopub.status.busy": "2024-11-24T08:25:21.692518Z",
     "iopub.status.idle": "2024-11-24T08:25:21.700623Z",
     "shell.execute_reply": "2024-11-24T08:25:21.699388Z"
    },
    "papermill": {
     "duration": 0.02508,
     "end_time": "2024-11-24T08:25:21.702720",
     "exception": false,
     "start_time": "2024-11-24T08:25:21.677640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'education', 'default', 'balance', 'housing', 'loan', 'duration',\n",
       "       'campaign', 'pdays', 'previous', 'target', 'last_contact_day',\n",
       "       'last_contact_month', 'last_contact_year', 'job_blue-collar',\n",
       "       'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired',\n",
       "       'job_self-employed', 'job_services', 'job_student', 'job_technician',\n",
       "       'job_unemployed', 'job_unknown', 'marital_married', 'marital_single',\n",
       "       'poutcome_other', 'poutcome_success', 'poutcome_unknown',\n",
       "       'contact_telephone', 'contact_unknown'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "847097b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:21.729959Z",
     "iopub.status.busy": "2024-11-24T08:25:21.729612Z",
     "iopub.status.idle": "2024-11-24T08:25:21.861824Z",
     "shell.execute_reply": "2024-11-24T08:25:21.860422Z"
    },
    "papermill": {
     "duration": 0.149195,
     "end_time": "2024-11-24T08:25:21.864713",
     "exception": false,
     "start_time": "2024-11-24T08:25:21.715518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created: submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Ensure both training and test data have the same columns after one-hot encoding\n",
    "train_data, test_data = train_data.align(test_data, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Ensure the 'target' column is not present in the test set (since it's for prediction)\n",
    "test_data_features = test_data.drop(columns='target')\n",
    "\n",
    "# Scale both training and test data (features only)\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Fit and transform on training data\n",
    "X_test_scaled = scaler.transform(test_data_features)  # Only transform on test data\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_predictions = grid_search_lgb.predict(X_test_scaled)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_data.index,  # Use index for test data IDs\n",
    "    'target': ['yes' if pred == 1 else 'no' for pred in test_predictions]\n",
    "})\n",
    "\n",
    "# Save the submission\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file created: submission.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a772e1",
   "metadata": {
    "papermill": {
     "duration": 0.012537,
     "end_time": "2024-11-24T08:25:21.890405",
     "exception": false,
     "start_time": "2024-11-24T08:25:21.877868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "387caee6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:21.917691Z",
     "iopub.status.busy": "2024-11-24T08:25:21.917325Z",
     "iopub.status.idle": "2024-11-24T08:25:21.922488Z",
     "shell.execute_reply": "2024-11-24T08:25:21.921348Z"
    },
    "papermill": {
     "duration": 0.021847,
     "end_time": "2024-11-24T08:25:21.924768",
     "exception": false,
     "start_time": "2024-11-24T08:25:21.902921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='auc', random_state=42)\n",
    "# param_grid_xgb = {\n",
    "#     'n_estimators': [100, 200],\n",
    "#     'max_depth': [3, 6],\n",
    "#     'learning_rate': [0.1, 0.01],\n",
    "#     'subsample': [0.8, 1],\n",
    "#     'colsample_bytree': [0.8, 1]\n",
    "# }\n",
    "\n",
    "# grid_search_xgb = GridSearchCV(estimator=xgb_model, param_grid=param_grid_xgb,\n",
    "#                                scoring='f1_macro', cv=3, n_jobs=-1)\n",
    "# grid_search_xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # Print best parameters\n",
    "# print(\"Best Parameters for XGBoost:\", grid_search_xgb.best_params_)\n",
    "# print(\"Best Cross-Validated F1 Score for XGBoost:\", grid_search_xgb.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "096aa656",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:21.952428Z",
     "iopub.status.busy": "2024-11-24T08:25:21.952000Z",
     "iopub.status.idle": "2024-11-24T08:25:21.956993Z",
     "shell.execute_reply": "2024-11-24T08:25:21.955931Z"
    },
    "papermill": {
     "duration": 0.021374,
     "end_time": "2024-11-24T08:25:21.959040",
     "exception": false,
     "start_time": "2024-11-24T08:25:21.937666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_val_pred_xgb = best_xgb_model.predict(X_val_scaled)\n",
    "\n",
    "# # F1 Score for XGBClassifier\n",
    "# f1_xgb = f1_score(y_val, y_val_pred_xgb, average='macro')\n",
    "\n",
    "# # Confusion Matrix for XGBClassifier\n",
    "# cm_xgb = confusion_matrix(y_val, y_val_pred_xgb)\n",
    "\n",
    "# # Plot Confusion Matrix\n",
    "# plt.figure(figsize=(6, 4))\n",
    "# sns.heatmap(cm_xgb, annot=True, fmt='d', cmap='Blues', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
    "# plt.title(\"Confusion Matrix for XGBClassifier\")\n",
    "# plt.ylabel('Actual')\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.show()\n",
    "\n",
    "# print(f\"F1 Score for XGBClassifier: {f1_xgb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d614276b",
   "metadata": {
    "papermill": {
     "duration": 0.012547,
     "end_time": "2024-11-24T08:25:21.984249",
     "exception": false,
     "start_time": "2024-11-24T08:25:21.971702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f40ee16",
   "metadata": {
    "papermill": {
     "duration": 0.012509,
     "end_time": "2024-11-24T08:25:22.010187",
     "exception": false,
     "start_time": "2024-11-24T08:25:21.997678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "got 71.517"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "315e55fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:22.037579Z",
     "iopub.status.busy": "2024-11-24T08:25:22.037211Z",
     "iopub.status.idle": "2024-11-24T08:25:22.041709Z",
     "shell.execute_reply": "2024-11-24T08:25:22.040685Z"
    },
    "papermill": {
     "duration": 0.020623,
     "end_time": "2024-11-24T08:25:22.043785",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.023162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "275baf2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:22.072450Z",
     "iopub.status.busy": "2024-11-24T08:25:22.072035Z",
     "iopub.status.idle": "2024-11-24T08:25:22.076741Z",
     "shell.execute_reply": "2024-11-24T08:25:22.075668Z"
    },
    "papermill": {
     "duration": 0.021607,
     "end_time": "2024-11-24T08:25:22.078917",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.057310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Initialize the Logistic Regression model with L1 regularization (Lasso)\n",
    "# lasso = LogisticRegression(penalty='l1', solver='liblinear', max_iter=2000, random_state=42, C=0.05)\n",
    "\n",
    "# # Fit the model\n",
    "# lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # Select features with non-zero coefficients\n",
    "# model = SelectFromModel(lasso, prefit=True)\n",
    "# selected_features = X.columns[model.get_support()]  # Use the original column names\n",
    "\n",
    "# print(\"Selected features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9682abf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:22.107242Z",
     "iopub.status.busy": "2024-11-24T08:25:22.105893Z",
     "iopub.status.idle": "2024-11-24T08:25:22.111116Z",
     "shell.execute_reply": "2024-11-24T08:25:22.110253Z"
    },
    "papermill": {
     "duration": 0.021275,
     "end_time": "2024-11-24T08:25:22.113120",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.091845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import RFE\n",
    "# # Feature Selection using Recursive Feature Elimination (RFE) with Logistic Regression\n",
    "# log_reg = LogisticRegression(max_iter=2000, solver='lbfgs', random_state=42)\n",
    "# rfe = RFE(estimator=log_reg, n_features_to_select=10) \n",
    "# rfe.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # Get selected feature names\n",
    "# selected_features = X.columns[rfe.support_]\n",
    "# print(\"Selected features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c46e87",
   "metadata": {
    "papermill": {
     "duration": 0.01216,
     "end_time": "2024-11-24T08:25:22.137970",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.125810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37d18556",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:22.164887Z",
     "iopub.status.busy": "2024-11-24T08:25:22.164529Z",
     "iopub.status.idle": "2024-11-24T08:25:22.170324Z",
     "shell.execute_reply": "2024-11-24T08:25:22.169311Z"
    },
    "papermill": {
     "duration": 0.022201,
     "end_time": "2024-11-24T08:25:22.172680",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.150479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# X_train_selected1 = X_train[selected_features]\n",
    "# X_val_selected1 = X_val[selected_features]\n",
    "\n",
    "# # Re-scale selected features\n",
    "# X_train_selected = scaler.fit_transform(X_train_selected1)\n",
    "# X_val_selected = scaler.transform(X_val_selected1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9afe522",
   "metadata": {
    "papermill": {
     "duration": 0.012362,
     "end_time": "2024-11-24T08:25:22.197877",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.185515",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SGD Classifier model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4805b0c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:22.224644Z",
     "iopub.status.busy": "2024-11-24T08:25:22.224276Z",
     "iopub.status.idle": "2024-11-24T08:25:22.230023Z",
     "shell.execute_reply": "2024-11-24T08:25:22.228748Z"
    },
    "papermill": {
     "duration": 0.022007,
     "end_time": "2024-11-24T08:25:22.232350",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.210343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Initialize the SGDClassifier model\n",
    "# sgd_model = SGDClassifier(random_state=42)\n",
    "# # param_grid_sgd = {\n",
    "# #     'loss': ['hinge', 'log'],\n",
    "# #     'alpha': [0.001, 0.01, 0.1],\n",
    "# #     'max_iter': [1000, 2000],\n",
    "# #     'penalty': ['elasticnet', 'l2'],\n",
    "# #     'eta0': [0.01, 0.1],\n",
    "# #     'class_weight': ['balanced', None]\n",
    "# # }\n",
    "\n",
    "# param_grid_sgd = {\n",
    "#     'loss': ['hinge'],\n",
    "#     'alpha': [0.01],\n",
    "#     'max_iter': [1000],\n",
    "#     'penalty': ['elasticnet'],\n",
    "#     'eta0': [0.01],  \n",
    "#     'class_weight': ['balanced'] \n",
    "# }\n",
    "\n",
    "# # Initialize GridSearchCV\n",
    "# grid_search_sgd = GridSearchCV(estimator=sgd_model,  param_grid=param_grid_sgd,\n",
    "#                                scoring='f1_macro',cv=3,\n",
    "#                                 n_jobs=-1)\n",
    "\n",
    "# # Fit the model\n",
    "# grid_search_sgd.fit(X_train_selected, y_train)\n",
    "\n",
    "# # Get the best parameters and score\n",
    "# best_params_sgd = grid_search_sgd.best_params_\n",
    "# best_score_sgd = grid_search_sgd.best_score_\n",
    "# best_sgd_model = grid_search_sgd.best_estimator_\n",
    "\n",
    "# print(\"Best Parameters for SGDClassifier:\", best_params_sgd)\n",
    "# print(\"Best Cross-Validated F1 Score for SGDClassifier:\", best_score_sgd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17b4d2fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:22.261700Z",
     "iopub.status.busy": "2024-11-24T08:25:22.261306Z",
     "iopub.status.idle": "2024-11-24T08:25:22.266926Z",
     "shell.execute_reply": "2024-11-24T08:25:22.265700Z"
    },
    "papermill": {
     "duration": 0.022291,
     "end_time": "2024-11-24T08:25:22.269025",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.246734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Apply feature selection to the validation set\n",
    "# X_val_selected = X_val[selected_features]\n",
    "\n",
    "# # Scale the validation set (using the same scaler as for the training set)\n",
    "# X_val_selected_scaled = scaler.transform(X_val_selected)\n",
    "\n",
    "# # Make predictions on the validation set\n",
    "# test_predictions_val = best_sgd_model.predict(X_val_selected_scaled)\n",
    "\n",
    "# # Calculate F1 Score on validation set\n",
    "# f1_sgd_val = f1_score(y_val, test_predictions_val, average='macro')\n",
    "\n",
    "# # Confusion Matrix for SGDClassifier on Validation Set\n",
    "# cm_sgd_val = confusion_matrix(y_val, test_predictions_val)\n",
    "\n",
    "# # Plot Confusion Matrix for validation set\n",
    "# plt.figure(figsize=(6, 4))\n",
    "# sns.heatmap(cm_sgd_val, annot=True, fmt='d', cmap='Blues', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
    "# plt.title(\"Confusion Matrix for SGDClassifier (Validation Set)\")\n",
    "# plt.ylabel('Actual')\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.show()\n",
    "\n",
    "# print(f\"F1 Score for SGDClassifier on Validation Set: {f1_sgd_val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0439c46b",
   "metadata": {
    "papermill": {
     "duration": 0.012527,
     "end_time": "2024-11-24T08:25:22.294286",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.281759",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f5dc802",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:22.321246Z",
     "iopub.status.busy": "2024-11-24T08:25:22.320861Z",
     "iopub.status.idle": "2024-11-24T08:25:22.325693Z",
     "shell.execute_reply": "2024-11-24T08:25:22.324395Z"
    },
    "papermill": {
     "duration": 0.020931,
     "end_time": "2024-11-24T08:25:22.327834",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.306903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X_test_selected = test_data[selected_features]\n",
    "# X_test_selected_scaled = scaler.transform(X_test_selected)\n",
    "# test_predictions = best_sgd_model.predict(X_test_selected_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e10d75a",
   "metadata": {
    "papermill": {
     "duration": 0.012364,
     "end_time": "2024-11-24T08:25:22.352956",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.340592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "416a940f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:22.380620Z",
     "iopub.status.busy": "2024-11-24T08:25:22.380126Z",
     "iopub.status.idle": "2024-11-24T08:25:22.385570Z",
     "shell.execute_reply": "2024-11-24T08:25:22.384333Z"
    },
    "papermill": {
     "duration": 0.022195,
     "end_time": "2024-11-24T08:25:22.387999",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.365804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Insights : Got the highest f1 score by the SGD model : 0.75675"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68356fd9",
   "metadata": {
    "papermill": {
     "duration": 0.012452,
     "end_time": "2024-11-24T08:25:22.413328",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.400876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Random forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a39767d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:22.441342Z",
     "iopub.status.busy": "2024-11-24T08:25:22.440827Z",
     "iopub.status.idle": "2024-11-24T08:25:22.446840Z",
     "shell.execute_reply": "2024-11-24T08:25:22.445915Z"
    },
    "papermill": {
     "duration": 0.022333,
     "end_time": "2024-11-24T08:25:22.448974",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.426641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X = train_data.drop(columns='target')\n",
    "# y = train_data['target'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# # Step 1: Remove 'target' column if present in test_data\n",
    "# if 'target' in test_data.columns:\n",
    "#     test_data = test_data.drop(columns=['target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06c4c4d",
   "metadata": {
    "papermill": {
     "duration": 0.012385,
     "end_time": "2024-11-24T08:25:22.474395",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.462010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3dabd057",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:22.502136Z",
     "iopub.status.busy": "2024-11-24T08:25:22.501742Z",
     "iopub.status.idle": "2024-11-24T08:25:22.507710Z",
     "shell.execute_reply": "2024-11-24T08:25:22.506498Z"
    },
    "papermill": {
     "duration": 0.022609,
     "end_time": "2024-11-24T08:25:22.509779",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.487170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV , cross_val_score \n",
    "\n",
    "# rf_model = RandomForestClassifier(random_state=42)\n",
    "# # param_grid = {\n",
    "# #     'n_estimators': [50, 100, 200, 300], \n",
    "# #     'max_depth': [5, 10, 15, 20, None], \n",
    "# #     'min_samples_split': [2, 5, 10, 20],  \n",
    "# #     'min_samples_leaf': [1, 2, 4, 6],  \n",
    "# #     'max_features': ['sqrt', 'log2', None], \n",
    "# #     'oob_score': [True, False],  \n",
    "# #     'criterion': ['gini', 'entropy'], \n",
    "# #     'class_weight': [None, 'balanced'] \n",
    "# # }\n",
    "\n",
    "# param_grid = {'oob_score': [True], 'n_estimators': [300], 'min_samples_split': [2], \n",
    "#               'min_samples_leaf': [6], 'max_features': [None], 'max_depth': [None], \n",
    "#               'criterion': ['gini'], 'class_weight': ['balanced']}\n",
    "\n",
    "# grid_search = RandomizedSearchCV(\n",
    "#     estimator=rf_model,\n",
    "#     param_distributions=param_grid,\n",
    "#     n_iter=10, \n",
    "#     cv=3,      \n",
    "#     n_jobs=-1,  \n",
    "#     random_state=42,\n",
    "#     scoring='f1_macro' \n",
    "# )\n",
    "# grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "# print(\"Best hyperparameters :\", grid_search.best_params_)\n",
    "\n",
    "# # Get the best model from RandomizedSearchCV\n",
    "# best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# best_rf_model.fit(X_train_selected, y_train)\n",
    "\n",
    "\n",
    "# y_val_pred = best_rf_model.predict(X_val_selected)\n",
    "\n",
    "# # Evaluate the model on the validation set\n",
    "# print(\"Random Forest Model Performance on Validation Set:\")\n",
    "# print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "# print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dbf9f57c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:22.537164Z",
     "iopub.status.busy": "2024-11-24T08:25:22.536747Z",
     "iopub.status.idle": "2024-11-24T08:25:22.542355Z",
     "shell.execute_reply": "2024-11-24T08:25:22.541417Z"
    },
    "papermill": {
     "duration": 0.021814,
     "end_time": "2024-11-24T08:25:22.544602",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.522788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X_test_scaled = scaler.transform(test_data[selected_features])  # Scale the test set with selected features\n",
    "# test_predictions = best_rf_model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8be1605",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:22.572153Z",
     "iopub.status.busy": "2024-11-24T08:25:22.571770Z",
     "iopub.status.idle": "2024-11-24T08:25:22.577561Z",
     "shell.execute_reply": "2024-11-24T08:25:22.576694Z"
    },
    "papermill": {
     "duration": 0.022089,
     "end_time": "2024-11-24T08:25:22.579784",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.557695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#INsights : The f1_score for the test data fluctuated from 65% to 70% to this model after doing different changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce7e9f1",
   "metadata": {
    "papermill": {
     "duration": 0.012406,
     "end_time": "2024-11-24T08:25:22.604961",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.592555",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37788cfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:22.631867Z",
     "iopub.status.busy": "2024-11-24T08:25:22.631505Z",
     "iopub.status.idle": "2024-11-24T08:25:22.635988Z",
     "shell.execute_reply": "2024-11-24T08:25:22.634869Z"
    },
    "papermill": {
     "duration": 0.020568,
     "end_time": "2024-11-24T08:25:22.638120",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.617552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a758aaca",
   "metadata": {
    "papermill": {
     "duration": 0.012221,
     "end_time": "2024-11-24T08:25:22.663402",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.651181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1246007",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:22.690305Z",
     "iopub.status.busy": "2024-11-24T08:25:22.689909Z",
     "iopub.status.idle": "2024-11-24T08:25:22.694910Z",
     "shell.execute_reply": "2024-11-24T08:25:22.693751Z"
    },
    "papermill": {
     "duration": 0.020938,
     "end_time": "2024-11-24T08:25:22.696943",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.676005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# model_pipeline = Pipeline([\n",
    "#     ('feature_selection', SelectKBest(('pca', PCA(n_components=10, random_state=42)),  # PCA for f_classif, k=10)), \n",
    "# #     dimensionality reduction to 10 components\n",
    "#     ('knn', KNeighborsClassifier(n_neighbors=5)) \n",
    "# ])\n",
    "\n",
    "\n",
    "# model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # Step 4: Evaluate the model on validation data\n",
    "# y_val_pred = model_pipeline.predict(X_val)\n",
    "\n",
    "# # Print evaluation metrics\n",
    "# print(\"K-Nearest Neighbors Model Performance on Validation Data:\")\n",
    "# print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "# print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "# test_predictions = model_pipeline.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "491aeeb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:22.723675Z",
     "iopub.status.busy": "2024-11-24T08:25:22.723289Z",
     "iopub.status.idle": "2024-11-24T08:25:22.728073Z",
     "shell.execute_reply": "2024-11-24T08:25:22.726880Z"
    },
    "papermill": {
     "duration": 0.02044,
     "end_time": "2024-11-24T08:25:22.730145",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.709705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#insights : got approximately 70% accuracy thorugh this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b6a0ac9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:22.757908Z",
     "iopub.status.busy": "2024-11-24T08:25:22.757566Z",
     "iopub.status.idle": "2024-11-24T08:25:22.762026Z",
     "shell.execute_reply": "2024-11-24T08:25:22.760960Z"
    },
    "papermill": {
     "duration": 0.020718,
     "end_time": "2024-11-24T08:25:22.764069",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.743351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if 'target' in test_data.columns:\n",
    "#     test_data = test_data.drop(columns=['target'])\n",
    "# X_test_scaled = scaler.transform(test_data)\n",
    "# test_predictions = grid_search_sgd.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f66ec0",
   "metadata": {
    "papermill": {
     "duration": 0.012312,
     "end_time": "2024-11-24T08:25:22.789137",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.776825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "44b46e18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:22.815984Z",
     "iopub.status.busy": "2024-11-24T08:25:22.815644Z",
     "iopub.status.idle": "2024-11-24T08:25:22.820455Z",
     "shell.execute_reply": "2024-11-24T08:25:22.819156Z"
    },
    "papermill": {
     "duration": 0.020791,
     "end_time": "2024-11-24T08:25:22.822527",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.801736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# submission = pd.DataFrame({\n",
    "#     'id': test_data.index,  \n",
    "#     'target': ['yes' if pred == 1 else 'no' for pred in test_predictions]\n",
    "# })\n",
    "\n",
    "# # Save the submission\n",
    "# submission.to_csv('submission.csv', index=False)\n",
    "# print(\"Submission file created: submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41621a27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:22.849293Z",
     "iopub.status.busy": "2024-11-24T08:25:22.848931Z",
     "iopub.status.idle": "2024-11-24T08:25:22.853427Z",
     "shell.execute_reply": "2024-11-24T08:25:22.852556Z"
    },
    "papermill": {
     "duration": 0.020289,
     "end_time": "2024-11-24T08:25:22.855534",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.835245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Model names and corresponding F1 scores\n",
    "# models = ['SGD', 'Random Forest', 'XGBoost', 'KNN']\n",
    "# f1_scores = [0.756, 0.68, 0.71517, 0.69]\n",
    "\n",
    "# # Plotting the F1 scores as a bar graph\n",
    "# plt.figure(figsize=(6, 4))\n",
    "# plt.bar(models, f1_scores, color=['skyblue', 'lightgreen', 'coral', 'lightpink'])\n",
    "# plt.xlabel(\"Models\")\n",
    "# plt.ylabel(\"F1 Score\")\n",
    "# plt.ylim(0, 1)\n",
    "# plt.title(\"Comparison of F1 Scores for Different Models\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "695401cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:22.882882Z",
     "iopub.status.busy": "2024-11-24T08:25:22.882471Z",
     "iopub.status.idle": "2024-11-24T08:25:22.887654Z",
     "shell.execute_reply": "2024-11-24T08:25:22.886414Z"
    },
    "papermill": {
     "duration": 0.021489,
     "end_time": "2024-11-24T08:25:22.889861",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.868372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# import lightgbm as lgb\n",
    "# from sklearn.metrics import classification_report, f1_score, roc_auc_score\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "53406df4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:22.917406Z",
     "iopub.status.busy": "2024-11-24T08:25:22.916994Z",
     "iopub.status.idle": "2024-11-24T08:25:22.926808Z",
     "shell.execute_reply": "2024-11-24T08:25:22.925654Z"
    },
    "papermill": {
     "duration": 0.026047,
     "end_time": "2024-11-24T08:25:22.928968",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.902921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# import lightgbm as lgb\n",
    "# from sklearn.metrics import classification_report, f1_score\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Load your training data\n",
    "# # data = pd.read_csv('dataset.csv')\n",
    "\n",
    "# # Preprocessing: Extract year, month, and day from 'last contact date' if it exists\n",
    "# if 'last contact date' in data.columns:\n",
    "#     data['last contact date'] = pd.to_datetime(data['last contact date'], errors='coerce')\n",
    "#     data['contact_year'] = data['last contact date'].dt.year\n",
    "#     data['contact_month'] = data['last contact date'].dt.month\n",
    "#     data['contact_day'] = data['last contact date'].dt.day\n",
    "#     data.drop(columns=['last contact date'], inplace=True)\n",
    "\n",
    "# # Separate features and target\n",
    "# X = data.drop('target', axis=1)  # Replace 'target' with your actual target column name\n",
    "# y = data['target']              # Replace 'target' with your actual target column name\n",
    "\n",
    "# # Split data into training and validation sets\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# # Define categorical and numerical columns\n",
    "# categorical_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
    "# numerical_cols = [col for col in X_train.columns if col not in categorical_cols]\n",
    "\n",
    "# # Preprocessing for numerical and categorical features\n",
    "# categorical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "# ])\n",
    "\n",
    "# numerical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='mean'))\n",
    "# ])\n",
    "\n",
    "# # Combine transformers in a ColumnTransformer\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', numerical_transformer, numerical_cols),\n",
    "#         ('cat', categorical_transformer, categorical_cols)\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # Apply SMOTE to balance the classes\n",
    "# smote = SMOTE(random_state=42)\n",
    "\n",
    "# # Preprocess the training data and apply SMOTE\n",
    "# X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "# X_train_resampled, y_train_resampled = smote.fit_resample(X_train_preprocessed, y_train)\n",
    "\n",
    "# # Preprocess the validation data\n",
    "# X_val_preprocessed = preprocessor.transform(X_val)\n",
    "\n",
    "# # Define the LightGBM model\n",
    "# lgbm_model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# # Train the LightGBM model\n",
    "# lgbm_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# # Make predictions on the validation set\n",
    "# y_val_pred = lgbm_model.predict(X_val_preprocessed)\n",
    "\n",
    "# # Evaluate the model on validation data\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(y_val, y_val_pred))\n",
    "# print(\"Macro F1 Score:\", f1_score(y_val, y_val_pred, average='macro'))\n",
    "\n",
    "# # Feature Importance Visualization\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# lgb.plot_importance(lgbm_model, max_num_features=10, importance_type='split', figsize=(10, 6))\n",
    "# plt.title(\"Feature Importance\")\n",
    "# plt.show()\n",
    "\n",
    "# # Load and preprocess the test data\n",
    "# # test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "# # Apply the same preprocessing steps to the test data\n",
    "# if 'last contact date' in test_data.columns:\n",
    "#     test_data['last contact date'] = pd.to_datetime(test_data['last contact date'], errors='coerce')\n",
    "#     test_data['contact_year'] = test_data['last contact date'].dt.year\n",
    "#     test_data['contact_month'] = test_data['last contact date'].dt.month\n",
    "#     test_data['contact_day'] = test_data['last contact date'].dt.day\n",
    "#     test_data.drop(columns=['last contact date'], inplace=True)\n",
    "\n",
    "# # Separate features from the test data (do not drop 'target' in test data as it doesn't exist)\n",
    "# X_test = test_data\n",
    "\n",
    "# # Preprocess the test data\n",
    "# X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# test_predictions = lgbm_model.predict(X_test_preprocessed)\n",
    "\n",
    "# # Assuming 'id' exists in test_data, or you can generate it based on the index\n",
    "# submission = pd.DataFrame({\n",
    "#     'id': test_data.index,  # Adjust based on your test data's unique identifier (if available)\n",
    "#     'target': ['yes' if pred == 1 else 'no' for pred in test_predictions]\n",
    "# })\n",
    "\n",
    "# # Save the submission file\n",
    "# submission.to_csv('submission.csv', index=False)\n",
    "# print(\"Submission file created: submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ab68ed6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:25:22.956871Z",
     "iopub.status.busy": "2024-11-24T08:25:22.955603Z",
     "iopub.status.idle": "2024-11-24T08:25:22.961179Z",
     "shell.execute_reply": "2024-11-24T08:25:22.960261Z"
    },
    "papermill": {
     "duration": 0.021777,
     "end_time": "2024-11-24T08:25:22.963536",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.941759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if 'last contact date' in test_data.columns:\n",
    "#     test_data['last contact date'] = pd.to_datetime(test_data['last contact date'], errors='coerce')\n",
    "#     test_data['contact_year'] = test_data['last contact date'].dt.year\n",
    "#     test_data['contact_month'] = test_data['last contact date'].dt.month\n",
    "#     test_data['contact_day'] = test_data['last contact date'].dt.day\n",
    "#     test_data.drop(columns=['last contact date'], inplace=True)\n",
    "\n",
    "# # Separate features from the test data\n",
    "# X_test = test_data.drop('target', axis=1)  # Ensure 'target' is not in the test data\n",
    "\n",
    "# # Preprocess the test data\n",
    "# X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# test_predictions = lgbm_model.predict(X_test_preprocessed)\n",
    "\n",
    "# # Create the submission DataFrame\n",
    "# submission = pd.DataFrame({\n",
    "#     'id': test_data.index,  # or use 'id' column if it exists in the test dataset\n",
    "#     'target': ['yes' if pred == 1 else 'no' for pred in test_predictions]\n",
    "# })\n",
    "\n",
    "# # Save the submission file\n",
    "# submission.to_csv('submission.csv', index=False)\n",
    "# print(\"Submission file created: submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16216e65",
   "metadata": {
    "papermill": {
     "duration": 0.012298,
     "end_time": "2024-11-24T08:25:22.988576",
     "exception": false,
     "start_time": "2024-11-24T08:25:22.976278",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9578279,
     "sourceId": 85062,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13.781891,
   "end_time": "2024-11-24T08:25:23.824720",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-24T08:25:10.042829",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
